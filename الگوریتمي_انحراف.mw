الګوریتمي انحراف (Algorithmic bias) په یو کمپیوټري سیسټم کې سیستماتیکې او تکرار کېدونې تېروتنې توصیف کوي؛ هغه چې «ناسمې» پایلې رامنځته کوي لکه د الګوریتم د پام وړ عملکرد له مخې د متفاوتو لارو چارو څخه په ګټنې یو ډلې ته د بلې په پرتله «امتیاز» قائلېږي. 

دغه ډول انحراف کېدای شي د ګڼ شمېر لاملونو له مخې وي چې کېدای شي په هغو کې د الګوریتم طراحي، معلوماتو ته د کوډ ورکولو، راغونډولو او انتخاب ډول چې د الګوریتم څخه د ګټنې په زده کړه کې ترې کار اخیستل کېږي شامل شي، خو دغو ته محدود نه دی. د بېلګې په توګه، الګوریتمي انحراف د پلټونکو سیسټمونو او ټولنیزو رسنیو په اساساتو کې لیدل کېږي. دغه انحراف کېدلای شي د خصوصي حریم له غیر عمدي سرغړونې څخه د نژادي، جنسیتي، جنسي او قومي ټولنیز انحراف تر پیاوړتیا پورې اغېز ولري. د الګوریتمي انحراف مطالعه تر ډېره پورې هغو الګوریتمونو ته اړوندېږي چې «سیستماتیک او غیرعادلانه» انحراف منعکس کوي. په وروستیو کې دغه انحراف ته په قانوني اډانه لکه د اروپايي اتحادیې له خوا د اطلاعاتو د خوندیتوب په عمومي مقررې (۲۰۱۸ زکال) او د مصنوعي ځیرکتیا په وړاندیز شوي قانون (۲۰۲۱ زکال) کې پام شوی. 

په داسې حال چې الګوریتمونه د ټولنې، سیاست، بنسټونو او چلن د تنظیم په برخه کې خپلې وړتیاوې پراخوي، ټولن پوهانو هغو لارو ته پام کړی چې په هغو کې له وړاندې نه څرګندې شوې د وتو لارې او د اطلاعاتو لاس وهنه کولای شي په فزیکي نړۍ اغېز ولري. له دې امله چې الګوریتمونه تر ډېره پورې شنډ او بې پلوه په پام کې نیول کېږي خو په ناسمه توګه کولای شي چې له انساني تخصص څخه په زیاته کچه ځواک وړاندې کړي (تر یوه بریده د اتوماتیک کولو د اروايي انحراف د ښکارندې له امله)؛ همدارنګه په ځینو مواردو کې په الګوریتمونو باندې تکیه کولای شي دانساني مسئولیت ځایګی ونیسي. دغه ډول انحراف کېدای شي له وړاندې څخه د موجودو کلتوري، ټولنیزو یا سازماني تمو د پایلې په توګه د الګوریتم په طراحي کې د تخنیکي محدودیتونو له امله او یا هم د هغو مخاطبینو د نه انګېرل شوې استفادې له امله چې د یو سافټ ویر په لومړنۍ طراحي کې په پام کې نه دي نیول شوي؛ الګوریتمي سیسټم ته داخل کړای شي. 

الګوریتمي انحراف د ټاکنو له پایلو څخه نیولې په انلاین توګه د نفرت جوړونکو خبرو اترو د خپراوي تر مواردو پورې یادول کېږي. همدارنګه د جنايي عدالت، روغتیايي پالنو او استخدام په برخو کې د نژادي، ټولنیز – اقتصادي او جنسیتي تبعیض د ترکیب په مواردو کې یادول کېږي. دڅېرې پېژندلو په ټکنالوژۍ کې نسبي کمزورتیا چې له امله یې ډېرې تورې څېرې په سمه توګه نشي تشخیص کېدلای د تور پوستو وګړو له یو شمېر ناقانونه نیونو سره اړونده ده؛ هغه ستونزه چې له یو شمېر نا متعادله اطلاعاتو څخه سرچینه اخلي. د الګوریتمي انحراف په درک، تحقیق او کشف کې ستونزې د الګوریتمونو د ځانګړي ماهیت له امله چې معمولا د سوداګریزو اسرارو په توګه ګڼل کېږي دوام لري. آن هغه مهال چې کامله روڼتیا وړاندې کېږي، د ځانګړو الګوریتمونو پیچلتیا د هغو د عملکرد په درک کې ستونزې جوړوي. له دې سربېره الګوریتمونه کېدای شي تغیر وکړي او د وردوي او خروجي اړوند داسې غبرګون وښيي چې د وړاندوینې وړ نه وي او یا هم په اسانۍ سره د تحلیل په موخه بیاځلي تولید نه شي. په ډېری مواردو کې آن په یوه ویب پانه یا پروګرام کې د ارزونې په موخه واحد «الګوریتم» شتون نه لري، بلکې د هماغه سرویس د کار کوونکو ترمنځ د پروګرامونو او اطلاعاتو یو بل ته اړونده شبکه شتون لري. 

== اغېز ==

=== سوداګریز اغېز ===
شرکتي الګوریتمونه کولای شي په ناڅرګنده توګه د مالي تنظیماتو یا د شرکتونو ترمنځ هوکړو ته انحراف وکړي، پرته له دې چې کاروونکی یې وپوهېږي هغه چې کېدای شي په غلطۍ سره فکر وکړي چې دا بې پلوه دي. د بېلګې په توګه امریکن ایرلاین په ۱۹۸۰ مه لسیزه کې د الوتنو د لټون یو الګوریتم جوړ کړ. دغه پروګرام د بېلابېلو هوايي شرکتونو الوتنې خپلو پیرودونکو ته وړاندې کولې، خو له دې سره یې قیمت یا هوساینې ته له پام پرته د خپلو الوتنو تقویت په کې سنجش کړی و. د متحده ایالاتو په کانګرس کې د دغه هوايي شرکت مشر په زغرده توګه څرګنده کړه چې دغه سیسټم یې د سیالي کونکي مزیت په موخه د ترجیجي چلن له مخې جوړ کړی دی.  <ref name="Sandvig1">{{cite journal|last1=Sandvig|first1=Christian|last2=Hamilton|first2=Kevin|author-link3=Karrie Karahalios|last3=Karahalios|first3=Karrie|last4=Langbort|first4=Cedric|title=Auditing Algorithms: Research Methods for Detecting Discrimination on Internet Platforms|journal=64th Annual Meeting of the International Communication Association|date=22 May 2014|url=http://www-personal.umich.edu/~csandvig/research/Auditing%20Algorithms%20--%20Sandvig%20--%20ICA%202014%20Data%20and%20Discrimination%20Preconference.pdf|access-date=18 November 2017}}</ref><ref name="FriedmanNissenbaum">{{cite journal|last1=Friedman|first1=Batya|last2=Nissenbaum|first2=Helen|title=Bias in Computer Systems|journal=ACM Transactions on Information Systems|date=July 1996|volume=14|issue=3|pages=330–347|url=https://nissenbaum.tech.cornell.edu/papers/biasincomputers.pdf|access-date=10 March 2019|doi=10.1145/230538.230561|s2cid=207195759}}</ref>

په ۱۹۹۸ زکال کې هغې مقالې چې ګوګل لټون کونکی سیسټم په کې تشریح شوی و په کې راغلي و چې د دغې کمپنۍ بنسټګر د لګښت ورکړل شوې ځای ټاکنې اړوند د شفافیت پالیسي د خپل لټون په پایلو کې تعقیبوي او استدلال یې کاوه چې «د تبلیغاتو پر بنسټ لټون کوونکي سیسټمونه په ذاتي توګه د مصرف کوونکو پر ځای د تبلیغ کوونکو لوري ته انحراف لري». دغه انحراف کېدای شي د کاروونکي لپاره یوه «نه څرګندېدونکې» لاسوهنه وي. <ref name="Sandvig12">{{cite journal|last1=Sandvig|first1=Christian|last2=Hamilton|first2=Kevin|author-link3=Karrie Karahalios|last3=Karahalios|first3=Karrie|last4=Langbort|first4=Cedric|title=Auditing Algorithms: Research Methods for Detecting Discrimination on Internet Platforms|journal=64th Annual Meeting of the International Communication Association|date=22 May 2014|url=http://www-personal.umich.edu/~csandvig/research/Auditing%20Algorithms%20--%20Sandvig%20--%20ICA%202014%20Data%20and%20Discrimination%20Preconference.pdf|access-date=18 November 2017}}</ref>

==== انلاین کرکه پاروونکې څرګندونې ====
د فیس بوک د داخلي اسنادو پر بنسټ، فیس بوک په ۲۰۱۷ زکال کې داسې الګوریتم طراحي کړ چې د تور پوستو ماشومانو اړوند یې د سپین پوستو نارینه وو پر لیکه/انلاین کرکې پاروونکې څرګندونې او هغه څرګندونې چې د ارزونې پر بنسټ یې دغه ډول اعتراضي محتوا لرله؛ هیسته کولې. دغه الګوریتم چې د کمپیوټري پروګرامو او د محتوا د انساني ارزونکو له ترکیب څخه جوړ و د ځانګړو ډلو پر ځای د پراخو ټولګو څخه د خوندیتوب په موخه رامنځه شو. د بېلګې په توګه هغه لیکنې چې «مسلمانان» یې محکوم کول، بلاک کېدلې، په داسې حال کې چې نورو هغو به چې یوازې «راډیکال مسلمانان» یې په نښه کول اجازه یې لرله. <ref name="AngwinGrassegger">{{cite web|url=https://www.propublica.org/article/facebook-hate-speech-censorship-internal-documents-algorithms|title=Facebook's Secret Censorship Rules Protect White Men From Hate Speech But Not Black Children — ProPublica|last1=Angwin|first1=Julia|last2=Grassegger|first2=Hannes|date=28 June 2017|website=ProPublica|access-date=20 November 2017}}</ref><ref name="AngwinVarnerTobin">{{cite news|url=https://www.propublica.org/article/facebook-enabled-advertisers-to-reach-jew-haters|title=Facebook Enabled Advertisers to Reach 'Jew Haters' — ProPublica|last1=Angwin|first1=Julia|date=14 September 2017|work=ProPublica|access-date=20 November 2017|last2=Varner|first2=Madeleine|last3=Tobin|first3=Ariana}}</ref><ref>{{Cite conference|url=https://homes.cs.washington.edu/~msap/pdfs/sap2019risk.pdf|title=The Risk of Racial Bias in Hate Speech Detection|last1=Sap|first1=Maarten|last2=Card|first2=Dallas|last3=Gabriel|first3=Saadia|last4=Choi|first4=Yejin|last5=Smith|first5=Noah A.|book-title=Proceedings of the 57th Annual Meeting of the Association for Computational Linguist|publisher=Association for Computational Linguistics|location=Florence, Italy|date=28 July – 2 August 2019|pages=1668–1678|url-status=live|archive-url=https://web.archive.org/web/20190814194616/https://homes.cs.washington.edu/~msap/pdfs/sap2019risk.pdf|archive-date=2019-08-14}}</ref><ref>{{Cite web|url=https://www.vox.com/recode/2019/8/15/20806384/social-media-hate-speech-bias-black-african-american-facebook-twitter|title=The algorithms that detect hate speech online are biased against black people|last=Ghaffary|first=Shirin|website=Vox|date=15 August 2019|access-date=19 February 2020}}</ref>

==== څارنه ====
د یو بل سره تړلو کمرو سافټ ویر کېدای شي په ذاتي توګه سیاسي وګڼل شي ځکه داسې الګوریتمونو ته اړتیا لري څو عادي او غیر عادي چلندونه سره جلا او مالوم کړي چې کوم کسان په ځانګړي مهال کې ځانګړي مکان ته اړوند دي. ښوول شوې چې په یوه نژادي طیف کې د څېرو د پېژندنې لپاره په انځورونو کې د نژادي توپیرونو له امله د هغو اطلاعاتي زېرمې له محدودیت سره مخ کېږي. که چېرې ډیری انځورونه یو نژاد یا جنسیت ته اړوند وي سافټ ویر یې د هغه نژاد یا جنسیت نور غړي په ښه توګه تشخیص کولای شي.  <ref name="Furl2002">{{cite journal|last1=Furl|first1=N|date=December 2002|title=Face recognition algorithms and the other-race effect: computational mechanisms for a developmental contact hypothesis|journal=Cognitive Science|volume=26|issue=6|pages=797–815|doi=10.1207/s15516709cog2606_4|doi-access=free}}</ref><ref name="Raji-Gebru-Mitchell-2020">{{cite journal|last1=Raji|first1=Inioluwa Deborah|last2=Gebru|first2=Timnit|last3=Mitchell|first3=Margaret|last4=Buolamwini|first4=Joy|last5=Lee|first5=Joonseok|last6=Denton|first6=Emily|title=Saving Face: Investigating the Ethical Concerns of Facial Recognition Auditing|journal=Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society|date=7 February 2020|pages=145–151|doi=10.1145/3375627.3375820|url=https://dl.acm.org/doi/10.1145/3375627.3375820|publisher=Association for Computing Machinery|arxiv=2001.00964|isbn=9781450371100|s2cid=209862419}}</ref><ref name="IntronaWood">{{cite journal|last1=Introna|first1=Lucas|last2=Wood|first2=David|date=2004|title=Picturing algorithmic surveillance: the politics of facial recognition systems|url=http://nbn-resolving.de/urn:nbn:de:0168-ssoar-200675|journal=Surveillance & Society|volume=2|pages=177–198|access-date=19 November 2017}}</ref><ref>{{Cite journal|last1=Buolamwini|first1=Joy|last2=Gebru|first2=Timnit|date=2018|title=Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification|url=http://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf|journal=Proceedings of Machine Learning Research|volume=81|page=1|via=MLR Press}}</ref>

=== جنسي تبعیض ===
په ۲۰۱۱ زکال کې د همجنسګرایانو د اړیکې نیولو اپلیکیشن ګرینډر (Grindr) راپور خپور کړ چې د اندروید سټور د پلورنځي الګوریتم د هغوی اپلیکیشن له هغو پروګرامونو سره اړوند ښيي چې د جنسي مجرمانو د موندلو په موخه طراحي شوي او نیوکه کوونکي یې وايي چې هغوی په ناسمه توګه همجنسګرايي له پدوفیلي سره اړونده بولي. لیکوال مایک آنانی په دغه شرکت باندې په اتلانتیک مجله کې نیوکه وکړه او استدلال یې وکړ چې دغه ډول بنسټونه د همجنسګرایانو نارینه و په واسطه بدنامه کېږي. په ۲۰۰۹ زکال کې د امازون انلاین پلورنځي هغه مهال چې د «لویانو د محتویاتو» د بلاک کولو اړوند الګوریتم ته یې پراختیا ورکړه ۵۷۰۰۰ هغه کتابونه چې جنسي یا د همجنسګرایانو موضوعاتو ته اړوند کېدل لکه د Brokeback Mountain په نامه ناول چې د هغو د منتقدینو له خوا یې هم هیسته کول وستایل شول؛ د خپل پلورنځي له لیست هیسته کړل. <ref name="Ananny">{{cite web|last1=Ananny|first1=Mike|title=The Curious Connection Between Apps for Gay Men and Sex Offenders|url=https://www.theatlantic.com/technology/archive/2011/04/the-curious-connection-between-apps-for-gay-men-and-sex-offenders/237340/|website=The Atlantic|access-date=18 November 2017|date=2011-04-14}}</ref><ref name="Kafka2">{{cite web|last1=Kafka|first1=Peter|title=Did Amazon Really Fail This Weekend? The Twittersphere Says 'Yes,' Online Retailer Says 'Glitch.'|url=http://allthingsd.com/20090412/did-amazon-really-fail-this-weekend-the-twittersphere-says-yes/|website=AllThingsD|access-date=22 November 2017}}</ref><ref name="Kafka">{{cite web|last1=Kafka|first1=Peter|title=Amazon Apologizes for 'Ham-fisted Cataloging Error'|url=http://allthingsd.com/20090413/amazon-apologizes-for-ham-fisted-cataloging-error/|website=AllThingsD|publisher=AllThingsD|access-date=22 November 2017}}</ref><ref name="Gillespie et al">{{cite book|title=Media Technologies|last1=Gillespie|first1=Tarleton|last2=Boczkowski|first2=Pablo|last3=Foot|first3=Kristin|publisher=MIT Press|year=2014|isbn=9780262525374|location=Cambridge|pages=1–30}}</ref>

په ۲۰۱۹ زکال کې فیسبوک وموندله چې «زما د ښځینه ملګرو د انځورونو» لپاره لټون له یو شمېر لنډیزونو لکه «په لنډو جامو» یا د «ساحل په غاړه» سره شتون درلود. بر خلاف «زما د نارینه ملګرو د انځورونو» لپاره لټون هېڅ پایله نلرله. <ref>{{Cite news|url=https://www.wired.com/story/facebook-female-friends-photo-search-bug/|title=A 'Sexist' Search Bug Says More About Us Than Facebook|last=Matsakis|first=Louise|date=2019-02-22|magazine=Wired|access-date=2019-02-26|issn=1059-1028}}</ref>

همدارنګه موندل شوې چې د څېرې د تشخیص ټکنالوژي د درې جنسه وګړو د څېرې پېژندلو په برخه کې ستونزې لري. په ۲۰۱۸ زکال کې د اوبر د څېرې د تشخیص له سافټ ویرونو سره چې د خپل داخلي امنیتي سیسټم په موخه یې ترې ګټنه کوله د اوبر د هغو موټر چلونکو د ستونزو راپور شتون درلود چې جنسیتي تغیر یې درلود او یا هم د جنسیتي تغیر په حالت کې و. په پایله کې د اوبر د یو شمېر درې جنسه و چلوونکو اکونټونه وځنډول شول او د هغو لپاره یې د کرایې په بیه او همدارنګه شغلي بالقوه لګښت له ځانه سره درلود، دا ټول له دې امله و چې د څېرې پېژندلو سافټ ویر د هغو چلوونکو د څېرې په تشخیص کې ستونزه لرله چې جنسیت یې د بدلون په حال کې و. <ref>{{Cite web|url=https://www.vox.com/future-perfect/2019/4/19/18412674/ai-bias-facial-recognition-black-gay-transgender|title=Some AI just shouldn't exist|date=2019-04-19}}</ref><ref>{{Cite web|url=https://www.vox.com/future-perfect/2019/4/19/18412674/ai-bias-facial-recognition-black-gay-transgender|title=Some AI just shouldn't exist|last=Samuel|first=Sigal|date=2019-04-19|website=Vox|language=en|access-date=2019-12-12}}</ref>

=== د ګوګل لټون ===
په داسې حال کې چې کاروونکي په بشپړ ډول اتوماتیکې پایلې تولید کوي؛ ګوګل نه دی توانېدلی څو جنسي او نژاد پرسته متون په اتوماتیک ډول لرې کړي. د بېلګې په توګه صفیا نوبل په خپل کتاب ''ځپونکي الګوریتمونه: څه ډول لټون کوونکي سیسټمونه نژادپرستي پیاوړې کوي (''Algorithms of Oppression: How Search Engines Reinforce Racism'')'' کې د «تور پوستو نجونو» د پلټنې نمونې ته اشاره کوي چې په پایله کې یې فورنوګرافیک انځورونه را اوړي. ګوګل ادعا کړې چې د دغو پاڼو د پاکولو واک نلري او یوازې هغه مهال دغه چاره امکان لري چې غیرقانوني وګڼل شي. <ref>{{Cite book|title=Algorithms of Oppression: How Search Engines Reinforce Racism|last=Noble, Safiya Umoja|isbn=9781479837243|location=New York|oclc=987591529|date=2018-02-20}}</ref>

== سرچينې ==
